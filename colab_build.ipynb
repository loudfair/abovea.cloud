{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "name": "Epstein Search — Cloud Build"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epstein Files Search Engine — Cloud Build\n",
    "\n",
    "This notebook downloads all data sources, normalizes them, and builds the search index entirely in Google Colab.\n",
    "The final index is saved to your Google Drive so you can pull it into the GitHub repo.\n",
    "\n",
    "**Runtime**: ~15 min | **RAM**: ~8GB peak | **Drive space**: ~600MB for index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Where the final index will be saved\n",
    "DRIVE_OUTPUT = '/content/drive/MyDrive/epstein-search-index'\n",
    "!mkdir -p \"$DRIVE_OUTPUT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/loudfair/abovea.cloud.git /content/epstein-search\n",
    "%cd /content/epstein-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download all data sources\n",
    "Downloads from HuggingFace, GitHub, and Archive.org — all in the cloud, nothing local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the download portion of setup.sh\n",
    "!bash setup.sh 2>&1 | tee /content/setup.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check disk & memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil, shutil\n",
    "\n",
    "mem = psutil.virtual_memory()\n",
    "disk = shutil.disk_usage('/content')\n",
    "\n",
    "print(f\"RAM:  {mem.available / (1024**3):.1f} GB available / {mem.total / (1024**3):.1f} GB total\")\n",
    "print(f\"Disk: {disk.free / (1024**3):.1f} GB available / {disk.total / (1024**3):.1f} GB total\")\n",
    "print()\n",
    "!du -sh /content/epstein-search/downloads/ 2>/dev/null || echo 'No downloads yet'\n",
    "!du -sh /content/epstein-search/data/ 2>/dev/null || echo 'No data yet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run security audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python audit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Copy index to Google Drive\n",
    "Copies the built search index to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "INDEX_DIR = '/content/epstein-search/data/index'\n",
    "\n",
    "# Copy index files to Drive\n",
    "for f in os.listdir(INDEX_DIR):\n",
    "    src = os.path.join(INDEX_DIR, f)\n",
    "    dst = os.path.join(DRIVE_OUTPUT, f)\n",
    "    print(f'Copying {f} ({os.path.getsize(src) / (1024*1024):.1f} MB)...')\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "# Also copy the corpus for the web UI\n",
    "corpus_src = '/content/epstein-search/data/normalized/corpus.jsonl'\n",
    "if os.path.exists(corpus_src):\n",
    "    corpus_dst = os.path.join(DRIVE_OUTPUT, 'corpus.jsonl')\n",
    "    print(f'Copying corpus.jsonl ({os.path.getsize(corpus_src) / (1024*1024):.1f} MB)...')\n",
    "    shutil.copy2(corpus_src, corpus_dst)\n",
    "\n",
    "print(f'\\n✓ Index saved to Google Drive: {DRIVE_OUTPUT}')\n",
    "!du -sh \"$DRIVE_OUTPUT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create GitHub Release (optional)\n",
    "Uploads the index as a GitHub release so the repo can download it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and set your GitHub token to upload as a release\n",
    "# GITHUB_TOKEN = 'ghp_...'  # paste your token here\n",
    "#\n",
    "# !pip install -q requests\n",
    "# import requests, os, json\n",
    "#\n",
    "# REPO = 'loudfair/abovea.cloud'\n",
    "# TAG = 'index-v1'\n",
    "# headers = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "#\n",
    "# # Create release\n",
    "# r = requests.post(\n",
    "#     f'https://api.github.com/repos/{REPO}/releases',\n",
    "#     headers=headers,\n",
    "#     json={'tag_name': TAG, 'name': 'Search Index v1', 'body': 'Pre-built search index'}\n",
    "# )\n",
    "# release = r.json()\n",
    "# upload_url = release['upload_url'].replace('{?name,label}', '')\n",
    "#\n",
    "# # Tar the index\n",
    "# !cd /content/epstein-search/data && tar czf /tmp/search-index.tar.gz index/\n",
    "#\n",
    "# # Upload\n",
    "# with open('/tmp/search-index.tar.gz', 'rb') as f:\n",
    "#     r = requests.post(\n",
    "#         f'{upload_url}?name=search-index.tar.gz',\n",
    "#         headers={**headers, 'Content-Type': 'application/gzip'},\n",
    "#         data=f\n",
    "#     )\n",
    "# print(f'✓ Uploaded: {r.json().get(\"browser_download_url\", r.text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick test — verify the index works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python search.py --text \"flight log\" --limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next steps\n",
    "\n",
    "Your index is now in Google Drive at `MyDrive/epstein-search-index/`.\n",
    "\n",
    "To use it locally:\n",
    "```bash\n",
    "# Download from Drive to your local repo\n",
    "mkdir -p data/index data/normalized\n",
    "# Copy index files from Drive to data/index/\n",
    "# Copy corpus.jsonl from Drive to data/normalized/\n",
    "python app.py  # start the web UI\n",
    "```"
   ]
  }
 ]
}
